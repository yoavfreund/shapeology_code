{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "#from matplotlib import pyplot as plt\n",
    "import skimage\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(os.environ['REPO_DIR'])\n",
    "from extractPatches import patch_extractor\n",
    "from lib.utils import configuration, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CDF(x):\n",
    "    x=np.sort(x)\n",
    "    size=x.shape[0]\n",
    "    y=np.arange(0,size)/size\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_download_from_s3(rel_fp, recursive=True):\n",
    "    s3_fp = 's3://mousebrainatlas-data/' + rel_fp\n",
    "    local_fp = os.environ['ROOT_DIR'] + rel_fp\n",
    "\n",
    "    if os.path.exists(local_fp):\n",
    "        print('ALREADY DOWNLOADED FILE')\n",
    "        return\n",
    "\n",
    "    if recursive:\n",
    "        run('aws s3 cp --recursive {0} {1}'.format(s3_fp, local_fp))\n",
    "    else:\n",
    "        run('aws s3 cp {0} {1}'.format(s3_fp, local_fp))\n",
    "        \n",
    "def setup_upload_from_s3(rel_fp, recursive=True):\n",
    "    s3_fp = 's3://mousebrainatlas-data/' + rel_fp\n",
    "    local_fp = os.environ['ROOT_DIR'] + rel_fp\n",
    "\n",
    "    if recursive:\n",
    "        run('aws s3 cp --recursive {0} {1}'.format(local_fp, s3_fp))\n",
    "    else:\n",
    "        run('aws s3 cp {0} {1}'.format(local_fp, s3_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(patch,params,extractor):\n",
    "    tile=patch #cv2.imread(patch,0)\n",
    "    if params['preprocessing']['polarity']==-1:\n",
    "        tile = 255-tile\n",
    "    min_std=params['preprocessing']['min_std']\n",
    "    _std = np.std(tile.flatten())\n",
    "\n",
    "    extracted = []\n",
    "    if _std < min_std:\n",
    "        extracted.append([0] * 201)\n",
    "        time_DM = 0\n",
    "        time_transform = 0\n",
    "    else:\n",
    "        Stats = extractor.segment_cells(tile)\n",
    "        cells = extractor.extract_blobs(Stats,tile)\n",
    "        time_DM = extractor.timestamps[-1][1]-extractor.timestamps[0][1]\n",
    "        time_transform = 0\n",
    "        for i in range(1,len(extractor.timestamps)-1,2):\n",
    "            time_transform = time_transform+extractor.timestamps[i+1][1]-extractor.timestamps[i][1]\n",
    "        cells = pd.DataFrame(cells)\n",
    "        cells = cells[cells['padded_patch'].notnull()]\n",
    "        cells = cells.drop(['padded_patch','left','top'],1)\n",
    "        cells = np.asarray(cells)\n",
    "        for k in range(len(cells)):\n",
    "            cells[k][0] = cells[k][0][:10]\n",
    "        origin = np.concatenate((np.array(list(cells[:,0])),cells[:,1:]),axis=1)\n",
    "        for k in range(origin.shape[1]):\n",
    "            x, y = CDF(origin[:,k])\n",
    "            ten = [x[np.argmin(np.absolute(y-0.1*(j+1)))] for j in range(10)]\n",
    "            extracted.extend(ten)\n",
    "        extracted.extend([cells.shape[0]/100])\n",
    "    return extracted, time_DM, time_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALREADY DOWNLOADED FILE\n",
      "ALREADY DOWNLOADED FILE\n",
      "ALREADY DOWNLOADED FILE\n",
      "0.22107887268066406\n",
      "CPU times: user 161 ms, sys: 48.9 ms, total: 209 ms\n",
      "Wall time: 221 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0=time()\n",
    "stack = 'MD594'\n",
    "fp = os.path.join('CSHL_data_processed', stack, stack + '_sorted_filenames.txt')\n",
    "setup_download_from_s3(fp, recursive=False)\n",
    "with open(os.environ['ROOT_DIR']+fp, 'r') as f:\n",
    "    fn_idx_tuples = [line.strip().split() for line in f.readlines()]\n",
    "    section_to_filename = {int(idx): fn for fn, idx in fn_idx_tuples}\n",
    "\n",
    "fname = os.path.join('CSHL_data_processed', stack, 'All_patch_locations.pkl')\n",
    "setup_download_from_s3(fname, recursive=False)\n",
    "all_patch_locations = pickle.load(open(os.environ['ROOT_DIR']+fname, 'rb'), encoding='latin1')\n",
    "\n",
    "fname = os.path.join('CSHL_data_processed', stack, 'Annotation.npy')\n",
    "setup_download_from_s3(fname, recursive=False)\n",
    "annotation = np.load(os.environ['ROOT_DIR']+fname, allow_pickle = True, encoding='latin1')\n",
    "contours = pd.DataFrame(annotation)\n",
    "contours = contours.rename(columns={0:\"name\", 1:\"section\", 2:\"vertices\"})\n",
    "contours_grouped = contours.groupby('section')\n",
    "print(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.4 ms, sys: 1.71 ms, total: 6.11 ms\n",
      "Wall time: 10.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuiqian/Github/shapeology_code/scripts/lib/utils.py:22: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  self.D=yaml.load(open(yamlFile,'r'))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Parameters\n",
    "param = {}\n",
    "param['max_depth']= 3   # depth of tree\n",
    "param['eta'] = 0.2      # shrinkage parameter\n",
    "param['silent'] = 1     # not silent\n",
    "param['objective'] = 'binary:logistic' #'multi:softmax'\n",
    "param['nthread'] = 7 # Number of threads used\n",
    "param['num_class']=1\n",
    "num_round = 100\n",
    "\n",
    "yamlfile=os.environ['REPO_DIR']+'shape_params.yaml'\n",
    "params=configuration(yamlfile).getParams()\n",
    "\n",
    "cell_dir = os.environ['ROOT_DIR'] + 'CSHL_patches_features/MD589/'\n",
    "raw_images_root = 'CSHL_data_processed/'+stack+'/'+stack+'_prep2_lossless_gray/'\n",
    "features_fn = 'CSHL_grid_features/'\n",
    "if not os.path.exists(os.environ['ROOT_DIR']+features_fn):\n",
    "    os.mkdir(os.environ['ROOT_DIR']+features_fn)\n",
    "features_fn = features_fn+stack+'/'\n",
    "if not os.path.exists(os.environ['ROOT_DIR']+features_fn):\n",
    "    os.mkdir(os.environ['ROOT_DIR']+features_fn)\n",
    "\n",
    "savepath = 'CSHL_hsv/'\n",
    "if not os.path.exists(os.environ['ROOT_DIR']+savepath):\n",
    "    os.mkdir(os.environ['ROOT_DIR']+savepath)\n",
    "savepath = savepath+stack+'/'\n",
    "if not os.path.exists(os.environ['ROOT_DIR']+savepath):\n",
    "    os.mkdir(os.environ['ROOT_DIR']+savepath)\n",
    "\n",
    "resol = 0.46\n",
    "half_size = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'local',\n",
       " 'paths': {'s3stem': 's3://mousebraindata-open/MD657',\n",
       "  'patches': 'permuted',\n",
       "  'DiffusionMap': '/Users/kuiqian/Github/shapeology_code/notebooks/diffusionMap',\n",
       "  'scripts_dir': '/Users/kuiqian/Github//shapeology_code/scripts',\n",
       "  'data_dir': '/Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/'},\n",
       " 'preprocessing': {'polarity': -1,\n",
       "  'min_std': 10,\n",
       "  'offset': -20,\n",
       "  'min_area': 10},\n",
       " 'normalization': {'size_thresholds': [15, 51, 201]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run cmd= aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_prep2_lossless_gray/MD594-IHC24-2015.08.26-16.39.39_MD594_2_0071_prep2_lossless_gray.tif /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_data_processed/MD594/MD594_prep2_lossless_gray/MD594-IHC24-2015.08.26-16.39.39_MD594_2_0071_prep2_lossless_gray.tif\n",
      "CPU times: user 763 ms, sys: 642 ms, total: 1.41 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "section = 130\n",
    "img_fn = raw_images_root + section_to_filename[section] + '_prep2_lossless_gray.tif'\n",
    "setup_download_from_s3(img_fn, recursive=False)\n",
    "img = cv2.imread(os.environ['ROOT_DIR']+img_fn, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.53 ms, sys: 327 Âµs, total: 2.86 ms\n",
      "Wall time: 2.84 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m, n = img.shape\n",
    "\n",
    "\n",
    "polygons = [(contour['name'], contour['vertices']) \\\n",
    "            for contour_id, contour in contours_grouped.get_group(section).iterrows()]\n",
    "\n",
    "grid_fn = features_fn + str(section) + '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished in   0.8 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  79.8 seconds\n",
      "Allocation finished in  80.3 seconds\n",
      "Image finished in   6.5 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/SNR/SNR_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/SNR/SNR_130.tif\n",
      "130 SNR 1 / 7 110.2704930305481\n",
      "Train finished in   0.9 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  67.4 seconds\n",
      "Allocation finished in  67.9 seconds\n",
      "Image finished in   4.7 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/DC/DC_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/DC/DC_130.tif\n",
      "130 DC 2 / 7 95.47600388526917\n",
      "Train finished in   0.7 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  70.9 seconds\n",
      "Allocation finished in  71.4 seconds\n",
      "Image finished in   4.6 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/Sp5I/Sp5I_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/Sp5I/Sp5I_130.tif\n",
      "130 Sp5I 3 / 7 95.34137606620789\n",
      "Train finished in   0.6 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  61.3 seconds\n",
      "Allocation finished in  61.7 seconds\n",
      "Image finished in   3.1 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/VLL/VLL_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/VLL/VLL_130.tif\n",
      "130 VLL 4 / 7 85.24740624427795\n",
      "Train finished in   0.3 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  45.7 seconds\n",
      "Allocation finished in  46.1 seconds\n",
      "Image finished in   4.6 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/PBG/PBG_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/PBG/PBG_130.tif\n",
      "130 PBG 5 / 7 71.58044409751892\n",
      "Train finished in   0.6 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  50.7 seconds\n",
      "Allocation finished in  51.3 seconds\n",
      "Image finished in   5.9 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/Sp5O/Sp5O_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/Sp5O/Sp5O_130.tif\n",
      "130 Sp5O 6 / 7 82.66486883163452\n",
      "130 finished in 540.6 seconds\n",
      "CPU times: user 3min 23s, sys: 14.6 s, total: 3min 37s\n",
      "Wall time: 9min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extractor=patch_extractor(params)\n",
    "num_cells = 0\n",
    "grid_features = {}\n",
    "NotUpload = True\n",
    "count = 0\n",
    "tb = time()\n",
    "time_train = 0\n",
    "time_upload = 0\n",
    "time_features = 0\n",
    "time_DMs = 0\n",
    "time_transforms = 0\n",
    "num_patch = 0\n",
    "for contour_id, contour in polygons:\n",
    "    t0=time()\n",
    "    structure = contour_id\n",
    "    if structure not in all_patch_locations[section].keys():\n",
    "        continue\n",
    "    polygon = contour.copy()\n",
    "\n",
    "    if structure == '7n':\n",
    "        structure = '7nn'\n",
    "\n",
    "    subpath = savepath + structure + '/'\n",
    "    if not os.path.exists(os.environ['ROOT_DIR']+subpath):\n",
    "        os.mkdir(os.environ['ROOT_DIR']+subpath)\n",
    "    \n",
    "    t1=time()\n",
    "    fp = []\n",
    "    fp.append(cell_dir + structure + '/MD589_' + structure + '_positive.pkl')\n",
    "    fp.append(cell_dir + structure + '/MD589_' + structure + '_negative.pkl')\n",
    "    features = []\n",
    "    labels = []\n",
    "    for state in range(2):\n",
    "        clouds = pickle.load(open(fp[state], 'rb'))\n",
    "        features.extend(np.array(clouds))\n",
    "        labels.extend([1 - state] * len(clouds))\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    X_train = features\n",
    "    y_train = labels\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    bst = xgb.train(param, dtrain, num_round, verbose_eval=False)\n",
    "    time_train = time_train+time()-t1\n",
    "    print('Train finished in %5.1f seconds' % (time() - t1))\n",
    "    \n",
    "\n",
    "    if structure == '7nn':\n",
    "        structure = '7n'\n",
    "\n",
    "    negative = structure + '_surround_500um_noclass'\n",
    "\n",
    "    [left, right, up, down] = [int(max(min(all_patch_locations[section][negative][:, 0]) - half_size, 0)),\n",
    "                               int(min(np.ceil(max(all_patch_locations[section][negative][:, 0]) + half_size),\n",
    "                                       n - 1)),\n",
    "                               int(max(min(all_patch_locations[section][negative][:, 1]) - half_size, 0)),\n",
    "                               int(min(np.ceil(max(all_patch_locations[section][negative][:, 1]) + half_size),\n",
    "                                       m - 1))]\n",
    "    t2=time()\n",
    "    xs, ys = np.meshgrid(np.arange(left + half_size, right - half_size + 1, half_size * 2),\n",
    "                         np.arange(up + half_size, down - half_size + 1, half_size * 2), indexing='xy')\n",
    "    locations = np.c_[xs.flat, ys.flat]\n",
    "    inside = all_patch_locations[section][structure]\n",
    "    all_rows = locations.view([('', locations.dtype)] * locations.shape[1])\n",
    "    inside_rows = inside.view([('', inside.dtype)] * inside.shape[1])\n",
    "    outside = np.setdiff1d(all_rows, inside_rows).view(locations.dtype).reshape(-1, locations.shape[1])\n",
    "    windows = []\n",
    "    windows.append(inside)\n",
    "    windows.append(outside)\n",
    "    polygon[:, 0] = polygon[:, 0] - left\n",
    "    polygon[:, 1] = polygon[:, 1] - up\n",
    "    print('location finished in %5.1f seconds' % (time() - t2))\n",
    "\n",
    "    hsv = np.zeros([down - up + 1, right - left + 1, 3])\n",
    "    hsv[:, :, 2] = 1\n",
    "    single_time = 0\n",
    "    t3=time()\n",
    "    for state in range(2):\n",
    "        for index in range(len(windows[state])):\n",
    "            try:\n",
    "                t4=time()\n",
    "                x = int(float(windows[state][index][0]))\n",
    "                y = int(float(windows[state][index][1]))\n",
    "                patch = img[y - half_size:y + half_size, x - half_size:x + half_size].copy()\n",
    "                grid_index = str(section)+'_'+str(x)+'_'+str(y)\n",
    "                if grid_index in grid_features.keys():\n",
    "                    extracted = grid_features[grid_index]\n",
    "                else:\n",
    "                    extracted, time_DM, time_transform = features_extractor(patch, params, extractor)\n",
    "                    grid_features[grid_index] = extracted\n",
    "                    time_DMs += time_DM\n",
    "                    time_transforms += time_transform\n",
    "                    num_patch += 1\n",
    "                    num_cells += len(extracted)\n",
    "                single_time=single_time+time()-t4\n",
    "                \n",
    "                xtest = xgb.DMatrix(extracted)\n",
    "                score = bst.predict(xtest, output_margin=True, ntree_limit=bst.best_ntree_limit)\n",
    "                value_img = patch / 255\n",
    "                hsv[y - half_size - up:y + half_size - up, x - half_size - left:x + half_size - left, 2] = value_img\n",
    "                satua_img = np.zeros_like(value_img) + score\n",
    "                origin = hsv[y - half_size - up:y + half_size - up, x - half_size - left:x + half_size - left, 1]\n",
    "                comp = np.absolute(origin) - np.absolute(satua_img)\n",
    "                hsv[y - half_size - up:y + half_size - up, x - half_size - left:x + half_size - left, \\\n",
    "                1] = origin * (comp > 0) + satua_img * (comp < 0)\n",
    "            except:\n",
    "                continue\n",
    "    time_features=time_features+single_time\n",
    "    print('Features finished in %5.1f seconds' % (single_time))\n",
    "    print('Allocation finished in %5.1f seconds' % (time() - t3))\n",
    "    t5=time()\n",
    "    hsv[:, :, 0] = (hsv[:, :, 1] < 0) * 0.66 + (hsv[:, :, 1] > 0) * 1.0\n",
    "    hsv[:, :, 1] = np.absolute(hsv[:, :, 1])\n",
    "    hsv[:, :, 1] = (hsv[:, :, 1] - hsv[:, :, 1].min()) / (hsv[:, :, 1].max() - hsv[:, :, 1].min()) * 0.8 + 0.2\n",
    "    rgb = skimage.color.hsv2rgb(hsv)\n",
    "    rgb = rgb * 255\n",
    "    rgb = rgb.astype(np.uint8)\n",
    "    com = cv2.polylines(rgb.copy(), [polygon.astype(np.int32)], True, [0, 255, 0], 15, lineType=8)\n",
    "    filename = subpath + structure + '_' + str(section) + '.tif'\n",
    "    cv2.imwrite(os.environ['ROOT_DIR']+filename, com)\n",
    "    print('Image finished in %5.1f seconds' % (time() - t5))\n",
    "    \n",
    "    t6=time()\n",
    "    setup_upload_from_s3(filename, recursive=False)\n",
    "    time_upload=time_upload+time()-t6\n",
    "    count += 1\n",
    "    print(section, structure, count, '/', len(polygons), time()-t0)\n",
    "# if NotUpload:\n",
    "#     pickle.dump(grid_features, open(os.environ['ROOT_DIR'] + grid_fn, 'wb'))\n",
    "#     setup_upload_from_s3(grid_fn, recursive=False)\n",
    "#os.remove(os.environ['ROOT_DIR']+img_fn)\n",
    "print(str(section) + ' finished in %5.1f seconds' % (time() - tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuiqian/Github/venv/shapeology_venv/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['contour', 'f', 'hsv', 'stack', 'time', 'negative']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624.2383833522377"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cells/time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:   381.8 s\n",
      "Number of Patches: 1224\n",
      "Average time/Patch: 311.9 ms\n",
      "Compute DMs:        355.2 s, 0.930\n",
      "Transform Process:  353.3 s, 0.925\n"
     ]
    }
   ],
   "source": [
    "print('Features:   %5.1f s'% (time_features)) \n",
    "print('Number of Patches:', num_patch)\n",
    "print('Average time/Patch: %5.1f ms'% (time_features/num_patch*1000))\n",
    "print('Compute DMs:        %5.1f s, %5.3f'% (time_DMs, time_DMs/time_features))\n",
    "print('Transform Process:  %5.1f s, %5.3f'% (time_transforms, time_transforms/time_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.04"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224*0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished in   0.8 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  93.4 seconds\n",
      "Allocation finished in  93.9 seconds\n",
      "Image finished in   6.7 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/SNR/SNR_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/SNR/SNR_130.tif\n",
      "130 SNR 1 / 7 127.13819003105164\n",
      "Train finished in   0.8 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  78.2 seconds\n",
      "Allocation finished in  78.7 seconds\n",
      "Image finished in   5.1 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/DC/DC_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/DC/DC_130.tif\n",
      "130 DC 2 / 7 107.2343738079071\n",
      "Train finished in   0.7 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  82.7 seconds\n",
      "Allocation finished in  83.2 seconds\n",
      "Image finished in   5.4 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/Sp5I/Sp5I_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/Sp5I/Sp5I_130.tif\n",
      "130 Sp5I 3 / 7 108.48069524765015\n",
      "Train finished in   0.6 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  72.1 seconds\n",
      "Allocation finished in  72.5 seconds\n",
      "Image finished in   4.6 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/VLL/VLL_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/VLL/VLL_130.tif\n",
      "130 VLL 4 / 7 101.84348487854004\n",
      "Train finished in   0.2 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  53.4 seconds\n",
      "Allocation finished in  53.8 seconds\n",
      "Image finished in   4.6 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/PBG/PBG_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/PBG/PBG_130.tif\n",
      "130 PBG 5 / 7 78.53807282447815\n",
      "Train finished in   0.7 seconds\n",
      "location finished in   0.0 seconds\n",
      "Features finished in  59.3 seconds\n",
      "Allocation finished in  60.0 seconds\n",
      "Image finished in   7.5 seconds\n",
      "run cmd= aws s3 cp /Users/kuiqian/BstemAtlasDataBackup/ucsd_brain/CSHL_hsv/MD594/Sp5O/Sp5O_130.tif s3://mousebrainatlas-data/CSHL_hsv/MD594/Sp5O/Sp5O_130.tif\n",
      "130 Sp5O 6 / 7 109.92123889923096\n",
      "130 finished in 633.2 seconds\n",
      "CPU times: user 3min 30s, sys: 1min, total: 4min 30s\n",
      "Wall time: 10min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_features = {}\n",
    "NotUpload = True\n",
    "count = 0\n",
    "tb = time()\n",
    "time_train = 0\n",
    "time_upload = 0\n",
    "time_features = 0\n",
    "time_DMs = 0\n",
    "time_transforms = 0\n",
    "num_patch = 0\n",
    "for contour_id, contour in polygons:\n",
    "    t0=time()\n",
    "    structure = contour_id\n",
    "    if structure not in all_patch_locations[section].keys():\n",
    "        continue\n",
    "    polygon = contour.copy()\n",
    "\n",
    "    if structure == '7n':\n",
    "        structure = '7nn'\n",
    "\n",
    "    subpath = savepath + structure + '/'\n",
    "    if not os.path.exists(os.environ['ROOT_DIR']+subpath):\n",
    "        os.mkdir(os.environ['ROOT_DIR']+subpath)\n",
    "    \n",
    "    t1=time()\n",
    "    fp = []\n",
    "    fp.append(cell_dir + structure + '/MD589_' + structure + '_positive.pkl')\n",
    "    fp.append(cell_dir + structure + '/MD589_' + structure + '_negative.pkl')\n",
    "    features = []\n",
    "    labels = []\n",
    "    for state in range(2):\n",
    "        clouds = pickle.load(open(fp[state], 'rb'))\n",
    "        features.extend(np.array(clouds))\n",
    "        labels.extend([1 - state] * len(clouds))\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    X_train = features\n",
    "    y_train = labels\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    bst = xgb.train(param, dtrain, num_round, verbose_eval=False)\n",
    "    time_train = time_train+time()-t1\n",
    "    print('Train finished in %5.1f seconds' % (time() - t1))\n",
    "    \n",
    "\n",
    "    if structure == '7nn':\n",
    "        structure = '7n'\n",
    "\n",
    "    negative = structure + '_surround_500um_noclass'\n",
    "\n",
    "    [left, right, up, down] = [int(max(min(all_patch_locations[section][negative][:, 0]) - half_size, 0)),\n",
    "                               int(min(np.ceil(max(all_patch_locations[section][negative][:, 0]) + half_size),\n",
    "                                       n - 1)),\n",
    "                               int(max(min(all_patch_locations[section][negative][:, 1]) - half_size, 0)),\n",
    "                               int(min(np.ceil(max(all_patch_locations[section][negative][:, 1]) + half_size),\n",
    "                                       m - 1))]\n",
    "    t2=time()\n",
    "    xs, ys = np.meshgrid(np.arange(left + half_size, right - half_size + 1, half_size * 2),\n",
    "                         np.arange(up + half_size, down - half_size + 1, half_size * 2), indexing='xy')\n",
    "    locations = np.c_[xs.flat, ys.flat]\n",
    "    inside = all_patch_locations[section][structure]\n",
    "    all_rows = locations.view([('', locations.dtype)] * locations.shape[1])\n",
    "    inside_rows = inside.view([('', inside.dtype)] * inside.shape[1])\n",
    "    outside = np.setdiff1d(all_rows, inside_rows).view(locations.dtype).reshape(-1, locations.shape[1])\n",
    "    windows = []\n",
    "    windows.append(inside)\n",
    "    windows.append(outside)\n",
    "    polygon[:, 0] = polygon[:, 0] - left\n",
    "    polygon[:, 1] = polygon[:, 1] - up\n",
    "    print('location finished in %5.1f seconds' % (time() - t2))\n",
    "\n",
    "    hsv = np.zeros([down - up + 1, right - left + 1, 3])\n",
    "    hsv[:, :, 2] = 1\n",
    "    single_time = 0\n",
    "    t3=time()\n",
    "    for state in range(2):\n",
    "        for index in range(len(windows[state])):\n",
    "            try:\n",
    "                t4=time()\n",
    "                x = int(float(windows[state][index][0]))\n",
    "                y = int(float(windows[state][index][1]))\n",
    "                patch = img[y - half_size:y + half_size, x - half_size:x + half_size].copy()\n",
    "                grid_index = str(section)+'_'+str(x)+'_'+str(y)\n",
    "                if grid_index in grid_features.keys():\n",
    "                    extracted = grid_features[grid_index]\n",
    "                else:\n",
    "                    extracted, time_DM, time_transform = features_extractor(patch, params)\n",
    "                    grid_features[grid_index] = extracted\n",
    "                    time_DMs += time_DM\n",
    "                    time_transforms += time_transform\n",
    "                    num_patch += 1\n",
    "                single_time=single_time+time()-t4\n",
    "                \n",
    "                xtest = xgb.DMatrix(extracted)\n",
    "                score = bst.predict(xtest, output_margin=True, ntree_limit=bst.best_ntree_limit)\n",
    "                value_img = patch / 255\n",
    "                hsv[y - half_size - up:y + half_size - up, x - half_size - left:x + half_size - left, 2] = value_img\n",
    "                satua_img = np.zeros_like(value_img) + score\n",
    "                origin = hsv[y - half_size - up:y + half_size - up, x - half_size - left:x + half_size - left, 1]\n",
    "                comp = np.absolute(origin) - np.absolute(satua_img)\n",
    "                hsv[y - half_size - up:y + half_size - up, x - half_size - left:x + half_size - left, \\\n",
    "                1] = origin * (comp > 0) + satua_img * (comp < 0)\n",
    "            except:\n",
    "                continue\n",
    "    time_features=time_features+single_time\n",
    "    print('Features finished in %5.1f seconds' % (single_time))\n",
    "    print('Allocation finished in %5.1f seconds' % (time() - t3))\n",
    "    t5=time()\n",
    "    hsv[:, :, 0] = (hsv[:, :, 1] < 0) * 0.66 + (hsv[:, :, 1] > 0) * 1.0\n",
    "    hsv[:, :, 1] = np.absolute(hsv[:, :, 1])\n",
    "    hsv[:, :, 1] = (hsv[:, :, 1] - hsv[:, :, 1].min()) / (hsv[:, :, 1].max() - hsv[:, :, 1].min()) * 0.8 + 0.2\n",
    "    rgb = skimage.color.hsv2rgb(hsv)\n",
    "    rgb = rgb * 255\n",
    "    rgb = rgb.astype(np.uint8)\n",
    "    com = cv2.polylines(rgb.copy(), [polygon.astype(np.int32)], True, [0, 255, 0], 15, lineType=8)\n",
    "    filename = subpath + structure + '_' + str(section) + '.tif'\n",
    "    cv2.imwrite(os.environ['ROOT_DIR']+filename, com)\n",
    "    print('Image finished in %5.1f seconds' % (time() - t5))\n",
    "    \n",
    "    t6=time()\n",
    "    setup_upload_from_s3(filename, recursive=False)\n",
    "    time_upload=time_upload+time()-t6\n",
    "    count += 1\n",
    "    print(section, structure, count, '/', len(polygons), time()-t0)\n",
    "# if NotUpload:\n",
    "#     pickle.dump(grid_features, open(os.environ['ROOT_DIR'] + grid_fn, 'wb'))\n",
    "#     setup_upload_from_s3(grid_fn, recursive=False)\n",
    "os.remove(os.environ['ROOT_DIR']+img_fn)\n",
    "print(str(section) + ' finished in %5.1f seconds' % (time() - tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4.019002199172974 0.006347129183785492\n",
      "Upload: 152.4430992603302 0.24075031468782404\n",
      "Features: 439.1544015407562 0.6935476966847065\n"
     ]
    }
   ],
   "source": [
    "total = 633.2\n",
    "print('Train:  ', time_train, time_train/total)\n",
    "print('Upload:', time_upload, time_upload/total)\n",
    "print('Features:', time_features, time_features/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:   439.2 s\n",
      "Number of Patches: 1224\n",
      "Average time/Patch: 358.8 ms\n",
      "Compute DMs:        406.8 s, 0.926\n",
      "Transform Process:  346.0 s, 0.788\n"
     ]
    }
   ],
   "source": [
    "print('Features:   %5.1f s'% (time_features)) \n",
    "print('Number of Patches:', num_patch)\n",
    "print('Average time/Patch: %5.1f ms'% (time_features/num_patch*1000))\n",
    "print('Compute DMs:        %5.1f s, %5.3f'% (time_DMs, time_DMs/time_features))\n",
    "print('Transform Process:  %5.1f s, %5.3f'% (time_transforms, time_transforms/time_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 141 ms, sys: 52.7 ms, total: 194 ms\n",
      "Wall time: 410 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = int(float(windows[1][5][0]))\n",
    "y = int(float(windows[1][5][1]))\n",
    "patch = img[y - half_size:y + half_size, x - half_size:x + half_size].copy()\n",
    "extractor=patch_extractor(patch,params)\n",
    "tile=patch #cv2.imread(patch,0)\n",
    "if params['preprocessing']['polarity']==-1:\n",
    "    tile = 255-tile\n",
    "min_std=params['preprocessing']['min_std']\n",
    "_std = np.std(tile.flatten())\n",
    "\n",
    "extracted = []\n",
    "if _std < min_std:\n",
    "    extracted.append([0] * 201)\n",
    "else:\n",
    "    Stats = extractor.segment_cells(tile)\n",
    "    cells = extractor.extract_blobs(Stats,tile)\n",
    "    cells = pd.DataFrame(cells)\n",
    "    cells = cells[cells['padded_patch'].notnull()]\n",
    "    cells = cells.drop(['padded_patch','left','top'],1)\n",
    "    cells = np.asarray(cells)\n",
    "    for k in range(len(cells)):\n",
    "        cells[k][0] = cells[k][0][:10]\n",
    "    origin = np.concatenate((np.array(list(cells[:,0])),cells[:,1:]),axis=1)\n",
    "    for k in range(origin.shape[1]):\n",
    "        x, y = CDF(origin[:,k])\n",
    "        ten = [x[np.argmin(np.absolute(y-0.1*(j+1)))] for j in range(10)]\n",
    "        extracted.extend(ten)\n",
    "    extracted.extend([cells.shape[0]/100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3839700222015381"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.timestamps[-1][1]-extractor.timestamps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3173530101776123"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = 0\n",
    "for i in range(1,len(extractor.timestamps)-1,2):\n",
    "    time=time+extractor.timestamps[i+1][1]-extractor.timestamps[i][1]\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapeology",
   "language": "python",
   "name": "shapeology_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
