import pickle as pk
import numpy as np
#from numpy import *
from glob import glob
import sys
import os
from lib.shape_utils import *
from lib.utils import configuration

from os import system
from os.path import isfile
import matplotlib.pyplot as plt

def dist2(a,b):
    diff=(a-b)**2
    return sum(diff.flatten())

class VQ_creator:
    """ a class for creating a VQ sequence """
    def __init__(self, params, _size):
        """
        Initialize a VQ sequence creator.
        :param params: parameters loaded from a yaml file
        :param _size: one of the three padded sizes
        """
        self.params = params
        self.size_thresholds = params['normalization']['size_thresholds']
        self.patch_dir = os.environ['ROOT_DIR'] + 'permute/permuted-' + str(_size)
        self.size = _size
        self.scale = 100

    def read_files(self):
        '''
        A generator loads each permuted file.
        :return: a 3D array consisting of patches
        '''
        for filename in glob(self.patch_dir+'/*.bin'):
            D=np.fromfile(filename,dtype=np.float16)
            pics=D.reshape([-1,self.size,self.size])
            print('in read_files filename=%s, shape=' % filename, pics.shape)
            yield pics

    def data_stream(self):
        '''
        A generator takes the 3D array from read-files() into patches.
        :return: one patch
        '''
        for pics in self.read_files():
            for i in range(pics.shape[0]):
                yield pics[i, :, :]

    def Kmeanspp(self, Reps=[], n=100):
        '''
        This function is to find representative samples of a specific number.
        :param Reps: initial representative sample set. Can be empty.
        :param n: the size of the final set
        :return: a list containing representative samples and a list recording the statistics of the process
        '''
        if len(Reps) == 0:
            # Reps = [next(self.data)]
            Reps = [self.data[0,:,:]]

        Statistics = []
        j = len(Reps)
        i = 0
        for patch in self.data:
            _min = 100000
            for r in Reps:
                _min = min(_min, dist2(patch, r))

            # if _min > self.scale:
            #     self.scale *= 1.5
            #     print('scale=', self.scale)

            Prob = _min / self.scale
            print('\r', 'i=%10d,  #reps=%10d  Prob=%8.6f,scale=%8.4f' % (i, len(Reps), Prob, self.scale), end='')
            i += 1
            Statistics.append((i, len(Reps), _min))
            if np.random.rand() < Prob:
                Reps.append(patch)
                j += 1
            if j >= n:
                break
            if Prob > 0.5:
                self.scale *= 2
            else:
                self.scale -= 1
        return Reps, Statistics

    def refineKmeans(self, data, Reps, per_rep_sample=25, refinement_iter=5):
        '''
        This function refine the representative sample set from Kmeanspp() based on the data not included in the Kmeanspp().
        Use representative samples to collect similar samples as clusters and then take the mean of each cluster.
        :param data: patches not used in the Kmeanspp() process
        :param Reps: the representative sample set generated by Kmeanspp()
        :param per_rep_sample: decide the data size of this process
        :param refinement_iter: the threshold for cluster size
        :return: a list containing the mean of patches in each cluster, a listing recording the cluster size
        '''
        _shape = Reps[0].shape
        new_Reps = [np.zeros(_shape) for r in Reps]
        _area = _shape[0] * _shape[1]
        Reps_count = [0.0 for r in Reps]
        error = 0
        count = per_rep_sample * len(Reps)
        i = 0
        for patch in data:
            dists = [dist2(patch, r) for r in Reps]
            _argmin = np.argmin(dists)
            _min = min(dists)
            new_Reps[_argmin] += patch
            Reps_count[_argmin] += 1
            error += _min
            i += 1
            if i >= count:
                break
        error /= (count * _area)
        final_Reps = []
        final_counts = []
        for i in range(len(new_Reps)):
            if Reps_count[i] > refinement_iter:
                final_Reps.append(new_Reps[i] / Reps_count[i])
                final_counts.append(Reps_count[i])
        return final_Reps, final_counts, error


    def Kmeans(self,Reps=[],n=100):
        '''
        The entire Kmeans process including Kmeanspp() and refineKmeans().
        :param Reps: initial representative sample set. Can be empty.
        :param n: the size of the target representative sample set by Kmeans++
        :return: The final list containing the mean of patches in each cluster and a listing recording the cluster size
        '''

        # self.data = self.data_stream()
        pics_list = []
        i = 0
        for pic in self.data_stream():
            pics_list.append(np.array(pic, dtype=np.float32))
            i += 1
            if i >= 500000:
                break
        self.data = pack_pics(pics_list)
        t0 = time()
        Reps,Statistics = self.Kmeanspp(Reps,n)
        print('Kmeans++ finished in',time()-t0,'seconds')
        for i in range(5):
            Reps,final_counts,error = self.refineKmeans(self.data[(i+1)*50000:(i+2)*50000,:,:],Reps)
            print('refine iteration %2d, error=%7.3f, n_Reps=%5d'%(i,error,len(Reps)))
        return Reps,final_counts



if __name__=='__main__':

    import argparse
    from time import time
    parser = argparse.ArgumentParser()
    parser.add_argument("padded_size", type=int,
                    help="One of the three padded size")
    parser.add_argument("yaml", type=str,
                    help="Path to Yaml file with parameters")
    
    # Add parameters for the size of patches and the path to the credential yaml file
    # Define file name based on size.
    
    args = parser.parse_args()
    size = args.padded_size
    config = configuration(args.yaml)
    params=config.getParams()
    root_dir = os.environ['ROOT_DIR']+'VQ/'
    if not os.path.exists((root_dir)):
        os.makedirs(root_dir)

    size_thresholds = params['normalization']['size_thresholds']
    # s3dir=params['paths']['patches']
    # gen=filtered_images(s3dir,smooth_threshold=0.35,reduce_res=True)
    t0 = time()
    VQ={}
    creator = VQ_creator(params, size)
    Reps, final_count = creator.Kmeans(n=2000)
    VQ[size] = (Reps, final_count)
    pk.dump(VQ, open(root_dir+'VQ'+str(size)+'.pkl', 'wb'))
    print('Finished in', time() - t0, 'seconds')
    # for n in self.size_thresholds:
    #     creator = VQ_creator(params, n)
    #     for c in range(10):
    #         print('========   n=%5d, c=%1d ==========='%(n,c))
    #         Reps,final_count=creator.Kmeans(gen,n=n)
    #         VQ[(n,c)]=(Reps,final_count)
    #
    #     #plot_patches(pack_pics(Reps),_titles=['n=%4d:#=%4d'%(n,x) for x in final_count])
    #
    # pk.dump(VQ,open('VQ5.pkl','wb'))
